{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83d5f790-552e-4eeb-88c0-47988a6e3c4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9be39ff-3bcd-41df-ab06-471c67b7d172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from delta.tables import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize Spark session with Delta Lake\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MasterCardAcquisition\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "777dc389-2771-46dd-ba63-4a7dea1de000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Read data and create schema, write as Delta in Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c2b9c01-9546-406a-84b6-50274247f8ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample data for different acquired companies\n",
    "companies_data = [\n",
    "    (1, \"PayTech Solutions\", \"US\", \"2023-01-15\", 50000000, \"payment_processing\"),\n",
    "    (2, \"CryptoFlow\", \"UK\", \"2023-02-20\", 75000000, \"cryptocurrency\"),\n",
    "    (3, \"LendFast\", \"Canada\", \"2023-03-10\", 30000000, \"lending\"),\n",
    "    (4, \"WalletSecure\", \"Germany\", \"2023-04-05\", 45000000, \"digital_wallet\"),\n",
    "    (5, \"InsurTech Pro\", \"France\", \"2023-05-12\", 60000000, \"insurance_tech\")\n",
    "]\n",
    "\n",
    "companies_schema = StructType([\n",
    "    StructField(\"company_id\", IntegerType(), True),\n",
    "    StructField(\"company_name\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"acquisition_date\", StringType(), True),\n",
    "    StructField(\"acquisition_value_usd\", LongType(), True),\n",
    "    StructField(\"business_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "companies_df = spark.createDataFrame(companies_data, companies_schema)\n",
    "\n",
    "# Write to Delta table\n",
    "companies_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/bronze/acquired_companies\")\n",
    "\n",
    "print(\"‚úÖ Delta table created successfully!\")\n",
    "companies_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9168f8cf-000e-4c7a-8286-9d82756c0a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Load from Bronze and create a table in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd0ea21d-5744-4a4c-b057-2cf7d45640fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Delta table\n",
    "acquired_companies = spark.read.format(\"delta\").load(\"/mnt/delta/bronze/acquired_companies\")\n",
    "\n",
    "# Alternative: Create table and query with SQL\n",
    "acquired_companies.write.format(\"delta\").saveAsTable(\"mastercard.acquired_companies\")\n",
    "\n",
    "# SQL query\n",
    "spark.sql(\"\"\"\n",
    "SELECT company_name, country, acquisition_value_usd \n",
    "FROM mastercard.acquired_companies \n",
    "WHERE acquisition_value_usd > 50000000\n",
    "ORDER BY acquisition_value_usd DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d97f63b-c22b-45bd-97c4-f7c60bcfdc3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Add more data as part of Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17dcf368-7d6f-4ce2-bd32-cee055b46b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's simulate data changes over time\n",
    "print(\" Initial version of data:\")\n",
    "spark.sql(\"SELECT * FROM mastercard.acquired_companies\").show()\n",
    "\n",
    "# Version 1: Add more companies\n",
    "new_companies = [\n",
    "    (6, \"BlockChain Innovations\", \"Singapore\", \"2023-06-18\", 80000000, \"blockchain\"),\n",
    "    (7, \"AI Financial\", \"Japan\", \"2023-07-22\", 95000000, \"ai_fintech\"),\n",
    "    (8, \"RegTech Solutions\", \"Australia\", \"2023-08-15\", 40000000, \"regulatory_tech\")\n",
    "]\n",
    "\n",
    "new_df = spark.createDataFrame(new_companies, companies_schema)\n",
    "new_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"mastercard.acquired_companies\")\n",
    "\n",
    "print(\"\\n After adding new companies (Version 2):\")\n",
    "spark.sql(\"SELECT COUNT(*) as total_companies FROM mastercard.acquired_companies\").show()\n",
    "\n",
    "# Version 2: Update acquisition values (market corrections)\n",
    "spark.sql(\"\"\"\n",
    "UPDATE mastercard.acquired_companies \n",
    "SET acquisition_value_usd = acquisition_value_usd * 1.1 \n",
    "WHERE business_type = 'cryptocurrency'\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n After updating crypto company values (Version 3):\")\n",
    "spark.sql(\"SELECT * FROM mastercard.acquired_companies WHERE business_type = 'cryptocurrency'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2dbbda7-7d35-45e5-b470-3d893a1d5db9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Schema Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5d195a-0cb7-41d8-b651-a3f9f464b9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulate new data with additional columns (schema evolution)\n",
    "extended_companies_data = [\n",
    "    (9, \"NeoBank Global\", \"Brazil\", \"2023-09-10\", 120000000, \"digital_banking\", \"Jo√£o Silva\", 850, True),\n",
    "    (10, \"PaySecure\", \"India\", \"2023-10-05\", 65000000, \"payment_security\", \"Priya Sharma\", 720, False),\n",
    "    # Update existing company with new schema\n",
    "    (2, \"CryptoFlow\", \"UK\", \"2023-02-20\", 82500000, \"cryptocurrency\", \"James Wilson\", 950, True)\n",
    "]\n",
    "\n",
    "extended_schema = StructType([\n",
    "    StructField(\"company_id\", IntegerType(), True),\n",
    "    StructField(\"company_name\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"acquisition_date\", StringType(), True),\n",
    "    StructField(\"acquisition_value_usd\", LongType(), True),\n",
    "    StructField(\"business_type\", StringType(), True),\n",
    "    StructField(\"ceo_name\", StringType(), True),  # New column\n",
    "    StructField(\"credit_score\", IntegerType(), True),  # New column\n",
    "    StructField(\"public_company\", BooleanType(), True)  # New column\n",
    "])\n",
    "\n",
    "extended_df = spark.createDataFrame(extended_companies_data, extended_schema)\n",
    "\n",
    "print(\"üîÑ New data with extended schema:\")\n",
    "extended_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84b8669b-908a-45e2-b387-86a08482c236",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Merge (Upsert) Operation\n",
    "####Comparing two data set if data available then set/update else just add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d220d48-c2e6-47de-9776-078ecb15094f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Delta table reference\n",
    "delta_table = DeltaTable.forName(spark, \"mastercard.acquired_companies\")\n",
    "\n",
    "# Perform merge (upsert) operation\n",
    "delta_table.alias(\"target\") \\\n",
    "    .merge(\n",
    "        extended_df.alias(\"source\"),\n",
    "        \"target.company_id = source.company_id\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdate(set = {\n",
    "        \"acquisition_value_usd\": \"source.acquisition_value_usd\",\n",
    "        \"ceo_name\": \"source.ceo_name\",\n",
    "        \"credit_score\": \"source.credit_score\",\n",
    "        \"public_company\": \"source.public_company\"\n",
    "    }) \\\n",
    "    .whenNotMatchedInsert(values = {\n",
    "        \"company_id\": \"source.company_id\",\n",
    "        \"company_name\": \"source.company_name\",\n",
    "        \"country\": \"source.country\",\n",
    "        \"acquisition_date\": \"source.acquisition_date\",\n",
    "        \"acquisition_value_usd\": \"source.acquisition_value_usd\",\n",
    "        \"business_type\": \"source.business_type\",\n",
    "        \"ceo_name\": \"source.ceo_name\",\n",
    "        \"credit_score\": \"source.credit_score\",\n",
    "        \"public_company\": \"source.public_company\"\n",
    "    }) \\\n",
    "    .execute()\n",
    "\n",
    "print(\"‚úÖ Merge operation completed!\")\n",
    "spark.sql(\"SELECT * FROM mastercard.acquired_companies ORDER BY company_id\").show()\n",
    "\n",
    "# Check schema evolution\n",
    "print(\"\\nüìã Current table schema:\")\n",
    "spark.sql(\"DESCRIBE mastercard.acquired_companies\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64604f86-bc6c-4f95-9889-35d9121a6c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Medallion Architecture (Bronze/Silver/Gold)\n",
    "####Bronze Layer (Raw Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5c0b2d-9ae4-41e3-b954-3a8f7926b4e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze: Raw transaction data from acquired companies\n",
    "raw_transactions = [\n",
    "    (1, 1, \"2023-12-01\", 150.75, \"USD\", \"purchase\", \"retail\"),\n",
    "    (2, 1, \"2023-12-01\", 2500.00, \"USD\", \"transfer\", \"p2p\"),\n",
    "    (3, 2, \"2023-12-01\", 0.05, \"BTC\", \"crypto_buy\", \"exchange\"),\n",
    "    (4, 3, \"2023-12-01\", 5000.00, \"CAD\", \"loan_disbursement\", \"lending\"),\n",
    "    (5, 4, \"2023-12-01\", 25.30, \"EUR\", \"wallet_load\", \"digital_wallet\")\n",
    "]\n",
    "\n",
    "bronze_schema = StructType([\n",
    "    StructField(\"transaction_id\", LongType(), True),\n",
    "    StructField(\"company_id\", IntegerType(), True),\n",
    "    StructField(\"transaction_date\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"transaction_type\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True)\n",
    "])\n",
    "\n",
    "bronze_df = spark.createDataFrame(raw_transactions, bronze_schema)\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/bronze/transactions\")\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"mastercard.bronze_transactions\")\n",
    "\n",
    "print(\"ü•â Bronze layer created - Raw transaction data\")\n",
    "bronze_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "598bdf84-6126-40ec-a44a-dbfc1b8a3f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Silver Layer - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13488ba5-ae14-4f90-b4dd-1105a5dc9aee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Silver: Cleaned and validated data\n",
    "silver_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    transaction_id,\n",
    "    company_id,\n",
    "    to_date(transaction_date, 'yyyy-MM-dd') as transaction_date,\n",
    "    amount,\n",
    "    upper(currency) as currency,\n",
    "    lower(transaction_type) as transaction_type,\n",
    "    lower(category) as category,\n",
    "    CASE \n",
    "        WHEN currency = 'USD' THEN amount\n",
    "        WHEN currency = 'EUR' THEN amount * 1.10  -- Simplified conversion\n",
    "        WHEN currency = 'CAD' THEN amount * 0.75\n",
    "        WHEN currency = 'BTC' THEN amount * 42000  -- Simplified BTC rate\n",
    "        ELSE amount\n",
    "    END as amount_usd,\n",
    "    current_timestamp() as processed_at\n",
    "FROM mastercard.bronze_transactions\n",
    "WHERE amount > 0 AND transaction_date IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/silver/transactions\")\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"mastercard.silver_transactions\")\n",
    "\n",
    "print(\"ü•à Silver layer created - Cleaned and standardized data\")\n",
    "silver_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dee75ab-38a5-4989-9a3c-927e15fb0287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daa75293-c63d-4a32-8a6c-f1aab4bc7d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold: Aggregated business metrics\n",
    "gold_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    c.company_name,\n",
    "    c.business_type,\n",
    "    c.country,\n",
    "    COUNT(t.transaction_id) as total_transactions,\n",
    "    SUM(t.amount_usd) as total_volume_usd,\n",
    "    AVG(t.amount_usd) as avg_transaction_usd,\n",
    "    MAX(t.transaction_date) as last_transaction_date,\n",
    "    current_timestamp() as report_generated_at\n",
    "FROM mastercard.silver_transactions t\n",
    "JOIN mastercard.acquired_companies c ON t.company_id = c.company_id\n",
    "GROUP BY c.company_name, c.business_type, c.country\n",
    "\"\"\")\n",
    "\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/gold/company_metrics\")\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"mastercard.gold_company_metrics\")\n",
    "\n",
    "print(\"ü•á Gold layer created - Business intelligence metrics\")\n",
    "gold_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "736dba5b-fafa-4a10-8121-08ad6229472e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Partitioning and Z-Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f291642-d072-4841-9c10-0d132c5174cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create large dataset for partitioning demonstration\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate sample transaction data across multiple months\n",
    "def generate_transactions(num_records=10000):\n",
    "    transactions = []\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        transaction_date = start_date + timedelta(days=random.randint(0, 365))\n",
    "        company_id = random.randint(1, 10)\n",
    "        amount = round(random.uniform(1, 10000), 2)\n",
    "        \n",
    "        transactions.append((\n",
    "            i + 1,\n",
    "            company_id,\n",
    "            transaction_date.strftime('%Y-%m-%d'),\n",
    "            amount,\n",
    "            random.choice(['USD', 'EUR', 'GBP', 'CAD']),\n",
    "            random.choice(['purchase', 'transfer', 'withdrawal', 'deposit']),\n",
    "            random.choice(['retail', 'online', 'atm', 'p2p'])\n",
    "        ))\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "large_transactions = generate_transactions(10000)\n",
    "large_df = spark.createDataFrame(large_transactions, bronze_schema)\n",
    "\n",
    "# Add year and month columns for partitioning\n",
    "partitioned_df = large_df.withColumn(\"year\", year(col(\"transaction_date\"))) \\\n",
    "                         .withColumn(\"month\", month(col(\"transaction_date\")))\n",
    "\n",
    "# Write partitioned table\n",
    "partitioned_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"/mnt/delta/silver/transactions_partitioned\")\n",
    "\n",
    "partitioned_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"mastercard.transactions_partitioned\")\n",
    "\n",
    "print(\"üìÇ Partitioned table created by year and month\")\n",
    "print(f\"Total records: {partitioned_df.count()}\")\n",
    "\n",
    "# Query performance comparison\n",
    "print(\"\\n‚ö° Querying partitioned data (should be faster):\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT company_id, COUNT(*) as transaction_count, SUM(amount) as total_amount\n",
    "FROM mastercard.transactions_partitioned \n",
    "WHERE year = 2023 AND month = 12\n",
    "GROUP BY company_id\n",
    "ORDER BY total_amount DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39c56161-7fa5-4920-9222-f2ff574ddd7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply Z-ordering for better query performance\n",
    "spark.sql(\"\"\"\n",
    "OPTIMIZE mastercard.transactions_partitioned\n",
    "ZORDER BY company_id, amount\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîÑ Z-ordering applied on company_id and amount columns\")\n",
    "\n",
    "# Check table details\n",
    "print(\"\\nüìä Table details after optimization:\")\n",
    "spark.sql(\"DESCRIBE DETAIL mastercard.transactions_partitioned\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09757052-11ae-4b5c-89af-8125caa10667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show table history before vacuum\n",
    "print(\"üóÇÔ∏è Table history before vacuum:\")\n",
    "spark.sql(\"DESCRIBE HISTORY mastercard.acquired_companies\").select(\"version\", \"timestamp\", \"operation\").show()\n",
    "\n",
    "# Set retention period (for demo purposes - normally 7 days minimum)\n",
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n",
    "\n",
    "# Vacuum old versions (removes old data files)\n",
    "spark.sql(\"VACUUM mastercard.acquired_companies RETAIN 0 HOURS\")\n",
    "print(\"\\nüßπ Vacuum completed - old data files removed\")\n",
    "\n",
    "# Note: In production, use appropriate retention period\n",
    "# spark.sql(\"VACUUM mastercard.acquired_companies RETAIN 168 HOURS\")  # 7 days\n",
    "\n",
    "# Try time travel after vacuum (should fail for older versions)\n",
    "print(\"\\n‚ö†Ô∏è Testing time travel after vacuum:\")\n",
    "try:\n",
    "    spark.sql(\"SELECT * FROM mastercard.acquired_companies VERSION AS OF 0\").show()\n",
    "except Exception as e:\n",
    "    print(f\"Expected error: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "573ceedc-7379-4e75-9c86-e24c1cc996aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mastercard_acquisition_pipeline():\n",
    "    \"\"\"\n",
    "    Complete data pipeline for MasterCard acquisition scenario\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting MasterCard Acquisition Data Pipeline\")\n",
    "    \n",
    "    # 1. Bronze: Ingest raw data\n",
    "    print(\"\\nü•â Bronze Layer: Ingesting raw data...\")\n",
    "    # (Code from bronze layer above)\n",
    "    \n",
    "    # 2. Silver: Clean and validate\n",
    "    print(\"\\nü•à Silver Layer: Cleaning and validating...\")\n",
    "    # (Code from silver layer above)\n",
    "    \n",
    "    # 3. Gold: Create business metrics\n",
    "    print(\"\\nü•á Gold Layer: Generating business insights...\")\n",
    "    # (Code from gold layer above)\n",
    "    \n",
    "    # 4. Optimize for performance\n",
    "    print(\"\\n‚ö° Optimizing tables for performance...\")\n",
    "    spark.sql(\"OPTIMIZE mastercard.silver_transactions\")\n",
    "    spark.sql(\"OPTIMIZE mastercard.gold_company_metrics ZORDER BY company_name\")\n",
    "    \n",
    "    # 5. Generate final report\n",
    "    print(\"\\nüìä Final Acquisition Summary Report:\")\n",
    "    spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        'Total Companies Acquired' as metric,\n",
    "        CAST(COUNT(*) AS STRING) as value\n",
    "    FROM mastercard.acquired_companies\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Total Acquisition Value (USD)' as metric,\n",
    "        CONCAT('$', FORMAT_NUMBER(SUM(acquisition_value_usd), 0)) as value\n",
    "    FROM mastercard.acquired_companies\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Average Company Value (USD)' as metric,\n",
    "        CONCAT('$', FORMAT_NUMBER(AVG(acquisition_value_usd), 0)) as value\n",
    "    FROM mastercard.acquired_companies\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Top Business Type' as metric,\n",
    "        business_type as value\n",
    "    FROM (\n",
    "        SELECT business_type, COUNT(*) as count\n",
    "        FROM mastercard.acquired_companies\n",
    "        GROUP BY business_type\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    print(\"\\n‚úÖ Pipeline completed successfully!\")\n",
    "\n",
    "# Run the complete pipeline\n",
    "mastercard_acquisition_pipeline()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DB_Operations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
